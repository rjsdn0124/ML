# Linear Regression

## 인공지능 신경망의 구성 방법
1. 데이터에 대한 이해
- 데이터셋에 대해 이해하고 이에 대한 구성을 파악하여 가설을 세우자!

2. 가설 수립
- 가설은 임의로 데이터 구성을 통해 추측해서 세워보는 식일 수 있고, 경험적으로 알고 있는 식일 수 있다. 
- 선형 회귀에서는 가설의 형태가 정해져 있음. Because, 선형회귀란 학습 데이터와 가장 잘 맞는 하나의 직선을 찾는 일이기 때문. 따라서, y = Wx + b || H(x) = Wx + b 형식을 따른다. 이때 W는 가중치, b를 편향이라고 한다.

3. 비용 함수에 대한 이해
- 비용함수(cost function) = 손실 함수(loss function) = 오차 함수(error function) = 목적 함수(objective function)
- 데이터들을 한 일차식으로 표현하는 것이 바로 선형 회귀이다. 하지만 이렇게 표현한 식이 데이터들과 정확히 일치할 수 없다. 따라서 여러개의 일직선들에 대해 데이터들과 가장 오차의 제곱 값의 평균이 가장 작게 만드는 식이 바로 훈련 데이터를 가장 잘 나타내는 직선일 것이다.
- 비용함수란 평균 제곱 오차와 같다. cost(W, b) = 평균 제곱 오차 계산 식과 같다.

4. 경사 하강법(Optimizer(최적화) algorytm)
- 가장 기본적인 옵티마이저 알고리즘.
- 가중치의 크기에 따라, 편향값의 크기에 따라 오차가 변함. 따라서 가장 오차가 작은 부분은 비용함수의 값이 가장 작은 부분일 것이고 이 부분은 W와 b에 따른 관계의 그래프에서 기울기가 0일 것이다. 이 논리를 이용해 해당 점에서의 기울기를 계산해 0에 가깝도록 기울기의 음양에 따라 이를 특정 숫자 a에 곱해주면서 계산해주는 방식이다.
여기서 a는 학습률을 나타내는데 이 값을 적당한 값으로 잘 찾아야 W의 값이 발산하는 경우 없이 빠른 학습이 가능하다.