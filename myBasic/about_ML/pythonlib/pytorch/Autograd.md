# Autograd

### 자동 미분
- requires_grad = True인 한 '스칼라' 텐서에 대한 수식이 있다면, 이 수식을 backward()함수를 통해 연산해서 해당 텐서에 기울기를 저장한다. w.grad 형태로 사용
- "reuqires_grad = True" param?
<br/> 해당 스칼라 텐서에 수식을 연산해서 나온 기울기를 저장하겠다는 선언

### forward & backward
- forward(순전파): 정답을 맞추기 위해 최선의 추측을 한다. 이렇게 추측을 하기 위해서 입력 데이터를 각 함수들에서 실행한다.

- backward(역전파): 발생한 오류에 비례하여 매개변수들의 값을 적절히 조절한다. Require_grad=True로 설정된 모든 텐서들에 대해 변화량을 계산하여준다. 해당 연산이 일어나면서 변화량이 저장된 공간에 새로 덮어 씌우는 게 아닌 그 위에 다시 한번 더 더해주는 효과를 일으켜서 이전 변화량과 중복하여 연산이 될 수 있으므로 optimizer.zero_grad()를 통해 초기화 시켜주어야 한다. 