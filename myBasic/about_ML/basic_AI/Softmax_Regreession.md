# Softmax Regression

## One-hot encoding
- 선택해야하는 선택지의 개수만큼의 차원을 가지면서, 각 선택지의 인덱스에 해당하는 원소에는 1, 나머지 원소는 0의 값을 가지도록 하는 표현방법이다. 다중 클래스 분류할 때 사용한다.
- One-hot encoding을 통해 표현된 벡터를 one-hot vector라 한다.

## one-hot vector 무작위성
- 굳이 이렇게 인덱스를 여러개 만들어서 각각에 대해서 0,1 처리를 해주어야 하냐는 생각이 들 수 있다. 그냥 인덱스 만들지 말고 정수를 레이블하여 차원을 하나만 가지면 될 수 있또록 레이블로 표현하면 되지만, 이러면 평균 제곱 오차를 구하게 되면 서로간의 차이가 모두 1이 되지 않으므로서 서로간에 관계성이 생겨버린다. 그래서 원핫방식을 사용하는게 좋다. but, 단어에 대해 관계성을 무시하므로 단어 서로간의 유사성을 구할 수도 없다.

## What is Softmax Regression
- 다중 클래스 분류 시 사용. 
<br/> logistic regression(이진 분류)이나 선형 회귀와는 다르게 여러개의 특성(feature)들을 통해서 다중 클래스의 값들 중 하나를 분류하는 함수.

- 선택지의 개수만큼의 차원을 가지는 벡터를 만들어서 해당 벡터가 벡터의 모든 원소의 합이 1이 되도록 원소들의 값을 변환시켜주는 함수를 지나야 한다. 이 함수를 소프트맥스 함수라 한다.

-  여러가지의 데이터 벡터를 선택지의 개수만큼의 차원을 가지는 벡터의 크기로 축소를 해야한다. 이전에는 하나의 입력값만 있었기에 각각의 가중치라는 개념이 없었는데, 소프트맥스 회귀에선 각각의 인덱스마다 각각의 x 데이터에 대한 전부 다 다른 가중치를 사용해서 오차를 줄여나가는 가중치로 값이 변경되어야 한다.

- softmax(WX+B)의 형태로 나타낼 수 있다. W는 class X feature. X는 feature x 1 으로 하여 형태를 class X 1 로 만들어준다. B는 class X 1 이다.

## 비용함수
### 크로스 엔트로피 함수
- 소프트맥스에서 사용.

- log함수를 통해 정답에 맞는 1이 들억가게 되면 자동으로 0이되어 오차가 없는 정확하게 예측한 상태가 되므로 옳은 함수. 굿굿굿이네 확률로 나온다면 1일 때의 확률만 고려가 되네, 나머지 0인 인덱스들은 무시.