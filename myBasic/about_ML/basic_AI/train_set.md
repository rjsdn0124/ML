# Train

## 학습 단위?

### epoch
- 전체 훈련 데이터가 한 신경망 학습에 순전파와 역전파를 통과해 한 번 사용된 주기를 말함. 
- epoch를 높일수록 해당 데이터 셋에 대한 높은 수준의 예측을 기대할 수 있다. 하지만, 이는 해당 데이터 셋에 '과적합'되어 다른 데이터의 입력에 대해 제대로 된 예측을 하지 못 할 수 있다.
### batch size
- 한 훈련 연산 한 번에 들어가는 데이터의 크기를 가리킨다.
- 1 batch size에 해당하는 데이터 셋을 mini batch라 한다.
- 1회 epoch안에 m개의 mini batch가 들어가며, m=1인 경우 이를 batch학습법이라 한다.
- 너무 큰 batch size의 경우엔 한번에 처리해야 할 데이터의 양이 많아지므로 학습 속도가 느려지고, 메모리 부족 문제 발생할 위험이 있다.
- 또한 너무 작은 경우엔 적은 데이터를 대상으로 가중치를 업데이트하는 현상이 자주 발생하므로 훈련이 불안정해진다.

### iteration
- 1epoch을 마치는데 필요한 파라미터 업데이트 수(= batch의 개수)

### Batch 경사 하강법
 - 전체 데이터가 한 batch가 되어 이 데이터들에 대해 경사하강법을 수행한다. 이걸 반복하는게 epoch 이 경우에는 최적값에 수렴하는 형태로 진행되지만, 계산량이 너무 많을 수 있다.
 - 만약 10개의 데이터가 있을 때 2개씩 나누어 준 데이터를 mini batch라 한다. 그리고 이 mini batch들을 5번 반복해준다 이를 iteration이라 한다.
 <br/> 만약 이 데이터로 수행하면 이를 mini batch 경사하강법이라 한다. 이 방법으로 한다면, 각 batch별로 계산이 계속 이루어지기 때문에 수렵 과정에서 많이 흔들릴 수 있지만, 데이터의 양이 작아 훈련 속도가 빠르다.