# Train

## 학습 단위?

### epoch
- 전체 훈련 데이터가 한 신경망 학습에 순전파와 역전파를 통과해 한 번 사용된 주기를 말함. 
- epoch를 높일수록 해당 데이터 셋에 대한 높은 수준의 예측을 기대할 수 있다. 하지만, 이는 해당 데이터 셋에 '과적합'되어 다른 데이터의 입력에 대해 제대로 된 예측을 하지 못 할 수 있다.
### batch size
- 한 훈련 연산 한 번에 들어가는 데이터의 크기를 가리킨다.
- 1 batch size에 해당하는 데이터 셋을 mini batch라 한다.
- 1회 epoch안에 m개의 mini batch가 들어가며, m=1인 경우 이를 batch학습법이라 한다.
- 너무 큰 batch size의 경우엔 한번에 처리해야 할 데이터의 양이 많아지므로 학습 속도가 느려지고, 메모리 부족 문제 발생할 위험이 있다.
- 또한 너무 작은 경우엔 적은 데이터를 대상으로 가중치를 업데이트하는 현상이 자주 발생하므로 훈련이 불안정해진다.

### iteration
- 1epoch을 마치는데 필요한 파라미터 업데이트 수(= batch의 개수)